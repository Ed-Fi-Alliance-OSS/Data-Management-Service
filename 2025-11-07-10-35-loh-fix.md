Ed‑Fi DMS LOH Stress Remediation Plan — 2025‑11‑07 10:35

Summary (Stakeholder)
- Problem: The Data Management Service allocates large strings and arrays on the .NET Large Object Heap (LOH) during common request paths (JSON request/response handling, schema validation, and query materialization). LOH objects (≥ ~85 KB) increase Gen2 garbage collections and fragment memory, driving CPU spikes and higher p95/p99 latency under load.
- Impact: Unnecessary allocations and repeated JSON conversions cause avoidable CPU and memory pressure, reducing throughput and increasing tail latency in bulk loads and large GET responses.
- Solution: Replace string-based JSON handling with streaming and direct UTF‑8 writes, cache compiled JSON Schemas, avoid stringify/parse cycles in validation, and stream query results directly from PostgreSQL to the response. Logging is guarded to avoid extra work when not emitted.
- Outcome: Lower allocation rate and Gen2 GC frequency, flatter memory usage, reduced CPU per request, and improved throughput/latency, especially for POST/PUT (validation heavy) and large GET queries.

Technical Background
- LOH stores large objects (≥ ~85,000 bytes). LOH collections occur with Gen2 GC and historically do not compact by default, which can fragment memory.
- Frequent large allocations (big strings/arrays) cause:
  - More Gen2 GCs (expensive, pauseful), increased CPU time.
  - Memory fragmentation and larger working set.
  - Latency spikes visible at p95/p99 and unpredictable performance under load.

Current DMS LOH Hotspots (as‑is)
- Response serialization (frontend)
  - `AspNetCoreFrontend.ToResult`: serializes `frontendResponse.Body` with a new `JsonSerializerOptions` and `WriteIndented = true`, then wraps it with `Results.Content(...)`.
  - File: src/dms/frontend/EdFi.DataManagementService.Frontend.AspNetCore/AspNetCoreFrontend.cs:104
- Request ingestion (frontend/core)
  - `ExtractJsonBodyFrom` reads the entire request body into a managed string; `ParseBodyMiddleware` then parses that string to `JsonNode`.
  - Files: src/dms/frontend/.../AspNetCoreFrontend.cs (body read), src/dms/core/.../Middleware/ParseBodyMiddleware.cs
- Document schema validation (core)
  - `DocumentValidator.Validate`: on every POST/PUT, serializes the resource’s schema `JsonNode` to a string and compiles a `JsonSchema` via `JsonSchema.FromText(...)`; then runs `Evaluate(...)`. It may re‑evaluate after each prune stage (overposted/null/whitespace), and uses stringify+parse inside prunes.
  - File: src/dms/core/EdFi.DataManagementService.Core/Validation/DocumentValidator.cs
- Query materialization (backend → frontend)
  - `SqlAction.GetAllDocumentsByResourceName` reads `EdfiDoc` then deserializes to `JsonNode`, collects into a `JsonArray`. Frontend re‑serializes again into a string response.
  - File: src/dms/backend/EdFi.DataManagementService.Backend.Postgresql/Operation/SqlAction.cs:196+
- Logging overhead (frontend/core)
  - Per‑request Info logs and sanitization run even when the level isn’t needed; body masking may double serialize/deserialize.
  - Files: src/dms/frontend/.../Infrastructure/LoggingMiddleware.cs, src/dms/core/.../Middleware/RequestResponseLoggingMiddleware.cs, src/dms/core/.../Middleware/RequestInfoBodyLoggingMiddleware.cs

Plan Overview (Developer)
Implement the following definitive changes. No fallbacks or incremental toggles are required.

1) Response JSON: direct UTF‑8 output and no pretty printing
- Replace string serialization with `Results.Json(frontendResponse.Body, jsonOptions)` and configure `HttpJsonOptions` once.
- Remove `WriteIndented = true` and avoid per‑request `new JsonSerializerOptions()`.
- Files:
  - src/dms/frontend/EdFi.DataManagementService.Frontend.AspNetCore/AspNetCoreFrontend.cs (ToResult)
  - src/dms/frontend/EdFi.DataManagementService.Frontend.AspNetCore/Program.cs (Configure `HttpJsonOptions` + ResponseCompression for GET)
- Implementation steps:
  - Add in Program.cs:
    - `builder.Services.ConfigureHttpJsonOptions(o => { o.SerializerOptions.Encoder = JavaScriptEncoder.UnsafeRelaxedJsonEscaping; o.SerializerOptions.DefaultIgnoreCondition = JsonIgnoreCondition.WhenWritingNull; });`
    - `builder.Services.AddResponseCompression(options => { options.EnableForHttps = true; options.MimeTypes = ResponseCompressionDefaults.MimeTypes.Concat(new[]{"application/json"}); });`
  - In `ToResult`, return `Results.Json(frontendResponse.Body, httpContext.RequestServices.GetRequiredService<IOptions<HttpJsonOptions>>().Value.SerializerOptions, frontendResponse.ContentType)` and remove the manual `JsonSerializer.Serialize` path and `WriteIndented`.

2) Request ingestion: stream parse and do not keep the raw body
- For POST/PUT only, parse via `HttpRequest.BodyReader` + `Utf8JsonReader/JsonDocument` in `ParseBodyMiddleware` (or `JsonDocument.ParseAsync` on `HttpContext.Request.Body`).
- Do not read the request into a string; remove `ExtractJsonBodyFrom` usage for GET/DELETE entirely.
- After successful parse, set `FrontendRequest.Body = null` to drop the large string immediately.
- Files:
  - src/dms/frontend/.../AspNetCoreFrontend.cs (stop reading body for GET/DELETE; pass through only needed metadata)
  - src/dms/core/.../Middleware/ParseBodyMiddleware.cs (switch to stream parsing; clear `FrontendRequest.Body`)
- Implementation outline:
  - Modify `AspNetCoreFrontend.FromRequest` to accept `bool readBody` and only read for POST/PUT. For reads, remove `StreamReader.ReadToEndAsync`; instead, leave `Body` null and rely on core to parse stream.
  - In `ParseBodyMiddleware`, replace `JsonNode.Parse(requestInfo.FrontendRequest.Body)` with parsing from `HttpContext.Request.Body` provided via request context (if needed, extend `FrontendRequest` to carry a stream reference for POST/PUT), or use a separate accessor to obtain the raw Stream.

3) Compiled JSON Schema cache for document validation
- Add `ICompiledSchemaCache` as a singleton: `ConcurrentDictionary<(string Resource, RequestMethod Method, Guid ReloadId), JsonSchema>`.
- Precompile Insert/Update schemas at API schema load/reload and populate the cache.
- Refactor `DocumentValidator` to:
  - Reuse a static `EvaluationOptions` instance.
  - Fetch the compiled `JsonSchema` from the cache instead of calling `JsonSchema.FromText(...)` per request.
- Files:
  - src/dms/core/EdFi.DataManagementService.Core/Validation/DocumentValidator.cs
  - src/dms/core/EdFi.DataManagementService.Core/ApiSchema (wire precompilation at schema load)
- Implementation outline:
  - Create `CompiledSchemaCache` service and register in `DmsCoreServiceExtensions.AddDmsDefaultConfiguration`.
  - On ApiSchema load/reload, iterate resources and precompile both Insert and Update schemas with the current `ReloadId`.
  - Change `DocumentValidator.GetSchema` to query the cache using `(resourceName, method, reloadId)`.

4) Pruning logic: in‑place mutation (no stringify/parse)
- Replace stringify+parse cycles inside prunes with direct mutation of `JsonObject`/`JsonArray` (they already return a pruned JsonObject). Assign the mutated object back without `ToJsonString()`/`Parse(...)`.
- Files:
  - src/dms/core/EdFi.DataManagementService.Core/Validation/DocumentValidator.cs (PruneOverpostedData, PruneNullData, whitespace prune)
- Implementation outline:
  - After `jsonObject.RemoveProperty(...)`, set `documentBody = jsonObject` (or the updated node) directly.
  - Ensure subsequent `Evaluate(...)` uses the mutated `JsonNode`.

5) Query response streaming (no in‑memory `JsonArray`)
- Stream query results directly from Npgsql to the HTTP response using `Utf8JsonWriter`.
- Replace `QueryResult.QuerySuccess(JsonArray)` with either:
  - a streaming result writer (e.g., `IResult` constructed via `Results.Stream(async (stream, ct) => { using var writer = new Utf8JsonWriter(stream); ... })`), or
  - `IAsyncEnumerable<JsonElement>` written by the frontend.
- Files:
  - src/dms/backend/.../Operation/SqlAction.cs (provide a streaming enumerator or writer instead of `JsonArray`)
  - src/dms/core/.../Handler/QueryRequestHandler.cs (return streaming `IResult`)
  - src/dms/core/.../External/Backend/QueryResult.cs (adjust shape to support streaming)
- Implementation outline:
  - In `SqlAction.GetAllDocumentsByResourceName`, iterate `NpgsqlDataReader` and for each row write its `EdfiDoc` `JsonElement` to `Utf8JsonWriter` (emit `[` at start, `,` between items, and `]` at end). For `TotalCount`, run count query first and write `Total-Count` header.
  - In the frontend handler, construct a streaming `IResult` that invokes the writer during response.

6) Logging: no work when not logging
- Guard high‑volume log statements with `IsEnabled(...)` and only sanitize within that block.
- Limit body masking to configured scenarios; when enabled, traverse with `Utf8JsonReader` and write to a pooled buffer.
- Files:
  - src/dms/frontend/.../Infrastructure/LoggingMiddleware.cs
  - src/dms/core/.../Middleware/RequestResponseLoggingMiddleware.cs
  - src/dms/core/.../Middleware/RequestInfoBodyLoggingMiddleware.cs

7) Optional buffer pooling
- Where temporary buffers are required (e.g., customizing writers), rent from `ArrayPool<byte>.Shared` and return after use.

Profiling & Validation Steps
- Baseline counters while running steady load (10–15 min):
  - `dotnet-counters monitor --process-id <PID> System.Runtime[alloc-rate,gc-heap-size,gen-2-gc-count,cpu-usage,threadpool-queue-length] Microsoft.AspNetCore.Hosting[requests-per-second,total-requests]`
- Capture traces focusing on allocations and GC:
  - `dotnet-trace collect -p <PID> --duration 00:00:30 --providers Microsoft-Windows-DotNETRuntime:0x4002000B:5,Microsoft-AspNetCore-Hosting`
  - Open the Speedscope report to confirm fewer GCAllocationTicks for LOH and reduced CPU in JSON functions.
- LOH confirmation via managed heap analysis:
  - `dotnet-gcdump collect -p <PID>` then `dotnet-gcdump analyze <file>` → confirm reduced large `System.String`/`char[]` and `JsonNode` sizes.
- Native+managed samples (optional but recommended on Linux):
  - `sudo perfcollect collect dms-loh --pid <PID>` → analyze with `perf report` or PerfView.

Unit & Perf Test Additions (beyond existing Core.Tests.Unit)
- New unit tests for compiled schema caching
  - Add a test double for `ICompiledSchemaCache` that counts factory invocations.
  - Call `DocumentValidator.Validate` twice for the same `(resource, method)` and `ReloadId`; assert the factory invoked only once.
- Prune no‑stringify tests
  - Add tests that verify prunes no longer call stringify+parse by asserting that the returned `JsonNode` reference remains an object mutated in place and that `JsonNode.Parse` is not used inside prune paths (refactor prune helpers to internal virtual methods and substitute a spy in tests).
- Request parsing tests (stream‑based)
  - Add tests for `ParseBodyMiddleware` that pass a request body via `Stream` and assert `FrontendRequest.Body` is null after parsing; verify large inputs parse without allocating a large string.
- Streaming query tests
  - Introduce a test that uses a fake `IQueryDocument` returning N documents and verifies the response is chunked (no `Content-Length`) and the output is valid JSON array with N elements; ensure no materialized `JsonArray` is created by asserting code paths taken (via fakes/spies).
- Logging guard tests
  - Verify that when `LogLevel.Information` is disabled, `LoggingSanitizer` is not invoked and allocation deltas around logger calls are minimal (use `GC.GetAllocatedBytesForCurrentThread()` within a narrow scope for a sanity check).
- Microbenchmarks (new project):
  - Add `EdFi.DataManagementService.Benchmarks` using BenchmarkDotNet with `[MemoryDiagnoser]` targeting:
    - `DocumentValidator.Validate` before vs after caching/prune changes.
    - Response writing: `Results.Content + Serialize` vs `Results.Json`.
    - Query path: materialize `JsonArray` vs streaming `Utf8JsonWriter`.

Success Criteria
- Allocation rate reduced by ≥ 20% on representative POST/PUT and large GET scenarios.
- Gen2 GC count per minute reduced measurably (target: ≥ 30% fewer under steady load).
- p95 latency improvement on write‑heavy flows and large GETs (target: ≥ 20% improvement).
- No regressions in functional tests and E2E.

Ownership & Sequence
1) Frontend/response changes (Results.Json + HttpJsonOptions + compression).
2) Request ingestion changes (stream parsing + clear Body for write requests).
3) Schema caching and prune refactor in core.
4) Streaming query path end‑to‑end.
5) Logging guards and buffer pooling where applicable.
6) Add unit/perf tests and re‑baseline with counters and traces.

Notes
- ApiSchema (schema‑of‑schemas) is already compiled once via `Lazy<JsonSchema>` in `ApiSchemaValidator`. This plan brings the resource document schema path to parity and eliminates stringify/parse loops that create LOH churn.

