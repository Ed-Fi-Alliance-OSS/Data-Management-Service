# DMS Concurrency Investigation – 2025‑11‑07

## Context
Performance testing shows the ASP.NET Core DMS process (PID 87917) plateaus around 245 % CPU (~2.5 cores) while PostgreSQL exposes only ~6 active sessions despite a 100‑connection pool. The Python load driver stays below one core, so the service layer is the bottleneck. The following code review highlights the most likely serialization points throttling request concurrency.

## Findings

### 1. API schema access is globally locked
- `ApiSchemaProvider.GetApiSchemaNodes()` wraps every read in a `lock (_reloadLock)` and performs the initial load/deep clone while holding that lock (`src/dms/core/EdFi.DataManagementService.Core/ApiSchema/ApiSchemaProvider.cs:507-566`).
- `ProvideApiSchemaMiddleware` then constructs a `VersionedLazy` that deep clones and merges every extension schema within its value factory (`src/dms/core/EdFi.DataManagementService.Core/Middleware/ProvideApiSchemaMiddleware.cs:25-86`). When the schema reload id changes (e.g., after an upload), the first request through each pipeline rebuilds the merged document while holding `_reloadLock`, forcing all other concurrent requests to wait.
- Because every handler (`Upsert`, `Query`, `Update`, `Delete`) pulls `ApiSchemaDocuments` through the same singleton provider, any long‑running schema recompute effectively serializes the entire pipeline, manifesting as low DB concurrency.

**Recommendations**
1. Replace the global `lock` with a `ReaderWriterLockSlim` or `AsyncLock` so steady‑state reads proceed concurrently while still protecting reloads.
2. Move the expensive deep clone/merge work outside the critical section by capturing `_apiSchemaNodes` under lock, then cloning/merging after releasing it; finally swap the reference with another short lock.
3. Precompute merged schemas at startup (and on upload) and push them into `IApiSchemaProvider`, avoiding per‑pipeline `VersionedLazy` cloning altogether.

### 2. Authorization pipeline performs serial remote calls per request
- Every API request runs through `ResourceActionAuthorizationMiddleware`, which calls `_claimSetProvider.GetAllClaimSets()` on the hot path (`src/dms/core/EdFi.DataManagementService.Core/Middleware/ResourceActionAuthorizationMiddleware.cs:135-156`).
- On cache expiration, `CachedClaimSetProvider` simply falls through to the underlying `ConfigurationServiceClaimSetProvider`, which synchronously obtains a token and downloads the entire authorization metadata set (`src/dms/core/EdFi.DataManagementService.Core/Security/ConfigurationServiceClaimSetProvider.cs:28-55`). There is no request coalescing, so a cache miss causes *every* in‑flight request to perform two blocking HTTP calls and JSON materialization while holding its Kestrel thread.
- After the claim set lookup, each authorization strategy validator opens additional PostgreSQL connections through `PostgresqlAuthorizationRepository` (`src/dms/backend/EdFi.DataManagementService.Backend.Postgresql/PostgresqlAuthorizationRepository.cs:8-68`). These calls run sequentially (e.g., ancestor hierarchy, student school, responsibility, staff, contact) and do not reuse the request’s existing transaction or pool connection. The result is a waterfall of dependent remote calls before the main document operation can even reach the database pool.

**Recommendations**
1. Wrap the claim‑set fetch in a `Lazy<Task<IList<ClaimSet>>>` or use `IMemoryCache.GetOrCreateAsync` to ensure only one request refreshes the cache while others await the same task. Consider refreshing claim sets proactively on a background timer instead of on the critical request path.
2. Cache authorization repository answers per token (e.g., per `TraceId` or per `ClientAuthorizations`) for the lifetime of the request to avoid re‑hitting PostgreSQL for the same student/edOrg combinations.
3. Pass the ambient `NpgsqlConnection`/transaction through authorization repository calls so the expensive `OpenConnectionAsync`/JSON deserialize cycles do not add more synchronous waits.
4. Profile this path with `dotnet-trace collect --process-id 87917 --providers Microsoft.AspNetCore.Hosting,System.Runtime,Npgsql` to confirm the time spent in `ConfigurationServiceClaimSetProvider` and `PostgresqlAuthorizationRepository` under load.

### 3. Cascade updates hold threads and transactions while doing CPU-heavy JSON rewrites
- The update pipeline keeps the PostgreSQL transaction open while invoking `recursivelyCascadeUpdates` (`src/dms/backend/EdFi.DataManagementService.Backend.Postgresql/Operation/UpdateDocumentById.cs:302-360`). That loop calls `_sqlAction.FindReferencingDocumentsByDocumentId` repeatedly and routes each document through `UpdateCascadeHandler.Cascade`, which deep clones `JsonNode` graphs and evaluates multiple `JsonPath` expressions (`src/dms/core/EdFi.DataManagementService.Core/Backend/UpdateCascadeHandler.cs:18-164`).
- Because this work is CPU bound, each request monopolizes both a Kestrel thread and a DB session for the entire cascade duration. Under load the CPU becomes saturated (observed 245 %), so only a handful of such requests progress far enough to issue subsequent queries, explaining the ~6 concurrent sessions.

**Recommendations**
1. Move cascade JSON mutations outside the SQL transaction where possible: fetch the referencing rows, release the transaction, compute the new JSON, then write back in a smaller transaction window.
2. Replace `JsonNode` cloning with `System.Text.Json` DOM projections (`JsonDocument`, `Utf8JsonReader`) or `Span<char>` parsing to cut allocations and CPU.
3. Run a focused profile of update calls with `dotnet-counters monitor --process-id 87917 System.Runtime[threadpool-queue-length,threadpool-completed-items] Microsoft.AspNetCore.Hosting --refresh 5` to watch the thread pool queue grow whenever cascades run.

### 4. Query streaming ties up request threads for entire result sets
- `QueryDocument.QueryDocuments` returns a `QuerySuccess` whose `WriteBodyAsync` opens a connection and iterates a `NpgsqlDataReader`, writing each row via `Utf8JsonWriter` on the request thread (`src/dms/backend/EdFi.DataManagementService.Backend.Postgresql/Operation/QueryDocument.cs:41-78`).
- There is no throttling or batching, so a single large result keeps the response thread and DB transaction alive until the whole array is serialized. Because serialization is CPU-heavy (`JsonElement` allocations plus writer flushes), throughput becomes CPU-bound well before PostgreSQL hits its pool limits.

**Recommendations**
1. Replace the manual `Utf8JsonWriter` loop with `IAsyncEnumerable<JsonElement>` streamed through `HttpResponseWriterExtensions.WriteAsJsonAsync` so the thread yields between batches.
2. Apply projection at the database level (e.g., `SELECT json_build_object(...)`) and write chunks with `await writer.WriteRawValueAsync(row, cancellationToken)` to reduce managed allocations.
3. Consider adding paging/`LIMIT` guards and enforcing `MaximumPageSize` at the controller boundary to prevent excessively long streaming responses tying up the worker pool.

## Profiling & Telemetry Plan
```bash
# Monitor thread pool usage, GC, and ASP.NET Core throughput every 5s
DOTNET_ThreadPool_MinThreads=200 \
dotnet-counters monitor --process-id 87917 \
    System.Runtime[threadpool-queue-length,threadpool-thread-count,gc-heap-size] \
    Microsoft.AspNetCore.Hosting[requests-per-second,current-requests]

# Capture a trace while the bottleneck manifests
DOTNET_ThreadPool_MinThreads=200 \
dotnet-trace collect --process-id 87917 \
    --providers Microsoft-AspNetCore-Server-Kestrel,System.Runtime,Npgsql \
    --duration 00:02:00 --output dms-concurrency.nettrace
```
Use `SpeedScope` or `dotnet-trace ps` to inspect whether time is spent waiting on `_reloadLock`, HTTP calls to CMS, or authorization SQL. Pair that with `SELECT * FROM pg_stat_activity WHERE application_name='EdFi.DMS';` to confirm session counts before/after changes.

## Next Steps
1. Implement schema lock refactor and benchmark with `wrk`/load harness to verify parallel requests no longer block during reloads.
2. Introduce claim-set refresh coalescing and request-scope caching for authorization repository calls; re-run the performance test to compare PostgreSQL session counts.
3. Optimize cascade and query serialization paths (JSON span-based mutations, smaller transaction windows) and validate with `dotnet-counters` that threadpool queues stay near zero.
4. Once code changes land, execute the load run again and capture updated telemetry to confirm we can drive significantly more than six concurrent database sessions before saturating CPU.
